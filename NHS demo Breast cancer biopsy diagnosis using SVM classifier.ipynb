{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Breast cancer biopsy diagnosis using Support Vector Machine classifier</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Histopathology images of cell nuclei. Biopsy samples taken from breast tissue using FNA.</center>\n",
    "\n",
    "\n",
    "<img src=\"FNA_breast_tissue.jpeg\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<font size=2 color=grey>Sizilio, Glaucia & Leite, Cicilia & Mg Guerreiro, Ana & Neto, Adriao Duarte. (2012). Fuzzy method for pre-diagnosis of breast cancer from the Fine Needle Aspirate analysis. Biomedical engineering online. 11. 83. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Aim:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a model to learn to predict **Benign** or **Malignant** for histopathology breast tumour biopsies.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Dataset:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset located at: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic%29\n",
    "\n",
    "Dataset contains 10 measurements (_features_) giving info about the cell nuclei obtained from the biopsy:\n",
    "\n",
    "    a) radius (mean of distances from center to points on the perimeter) \n",
    "    b) texture (standard deviation of gray-scale values) \n",
    "    c) perimeter \n",
    "    d) area \n",
    "    e) smoothness (local variation in radius lengths) \n",
    "    f) compactness (perimeter^2 / area - 1.0) \n",
    "    g) concavity (severity of concave portions of the contour) \n",
    "    h) concave points (number of concave portions of the contour) \n",
    "    i) symmetry \n",
    "    j) fractal dimension (\"coastline approximation\" - 1)\n",
    "    \n",
    "Dataset contains additional 20 derived features (mean, standard error, and \"worst\" i.e. mean of the three largest values) giving a total of 30 features.\n",
    "\n",
    "All of the examples in the dataset are _labelled_ with the \"correct\" diagnosis: B for benign and M for malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Data science approach:</font>\n",
    "\n",
    "    1) Import libraries\n",
    "    2) Import data\n",
    "    3) Exploratory data analysis\n",
    "    4) Create model\n",
    "    5) Evaluate model\n",
    "    Go back to steps 3 or 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) What format does our dataset currently exist in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that the sklearn version of the dataset exists as a base.Bunch - a 'dictionary-like' format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) What features (column headings) have we got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see parent level elements using .keys()... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the keys using typical pandas referencing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also access like this (if no spaces present)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dataset by means of the keys..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.keys() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap each key with print() function to display info nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(cancer['DESCR']) # shift o toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target']) # malignant = 0, benign = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we would assume that malignant = 0 and benign = 1.  (This info isn't explicitly stated in dataset description.)  Let's verify.  We know from description that there are that there are 357 benign cases.  If benign =1, then summing the target variables will give us 357.  Let's confirm this is the case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cancer.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Put data into dataframe format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dataframe for the dataset feature variables (leaving out the target data) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cancer['data'], columns=cancer['feature_names']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Look at structure of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can verify: \n",
    "\n",
    "    There are 30 features.\n",
    "    All are floats.\n",
    "    There are no missing values.\n",
    "    There are no NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above, we might ask if some of these features should be optimised to help the algorithm converge.  However for now, we'll go with the simplest approach first and just use the data 'as is'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels_df = df.assign(Benign = cancer['target']) # make a new df that has the labels\n",
    "data_and_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(data_and_labels_df, vars=['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "       'mean concave points', 'mean symmetry', 'mean fractal dimension'], hue='Benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = df.corr() # Find out correlation coefficients\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=14,10\n",
    "ax = sns.heatmap(coeffs, annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=6,6\n",
    "#sns.jointplot(data_and_labels_df['mean texture'], df['mean perimeter'], kind ='kde', color='red')\n",
    "sns.kdeplot(data_and_labels_df['mean area'], df['mean perimeter'], shade=True, cmap='plasma', shade_lowest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data_and_labels_df['mean area'], df['mean perimeter'], kind ='kde', color='red', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "sns.lmplot(x='mean area', y='mean perimeter', hue='Benign', data=data_and_labels_df, fit_reg=False, scatter_kws={'alpha':0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "sns.lmplot(x='mean texture', y='mean perimeter', hue='Benign', data=data_and_labels_df, fit_reg=False, scatter_kws={'alpha':0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Create model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Pull data into suitable structure for building model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our X matrix and y target data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df # We know this is a dataframe\n",
    "y = cancer.target # Let's see what type this is\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Split data into separate training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>4.3) Call our machine learning model, in this case Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Import and support vector machine class and instantiate...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>4.4) Train model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Fit machine learning model to training data...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Make predictions on test set (model has not seen this data yet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) See how well predictions match our known results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess performance using confusion matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred)) # col headings malignant (Class 0) benign (Class 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we note the following:\n",
    "\n",
    "    There are 66 actual class 0 (malignant) \n",
    "    There are 105 actual class 1 (benign)\n",
    "    \n",
    "It seems that our SVM is classifying everything as benign.  All actual class 0 (malignant) are coming out as false positives.  Let's look at the precision and recall..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess performance using Precision, Recall and F1 score metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, for class 1 (benign) recall = 1 (100%) because the SVM is actually finding _all_ the benign cases, but it is only doing this by classifying every sample as benign, i.e. it is also pulling in _all_ malignant cases (lots of false positives), so it's precision for this class is poor.\n",
    "\n",
    "Recall for class 0 (malignant) is zero because the SVM is unable to find these cases \n",
    "\n",
    "Obviously this is a very serious failing for a cancer detection system.  Where positive corresponds to benign, we would prefer false negatives (incorrectly diagnosing benign as malignant) rather than false positives (incorrectly classifying malignant cancers as benign - i.e. failing to spot malignant cancer)\n",
    "\n",
    "We need to adjust the parameters of the SVM (and perhaps consider normalising data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Data science is an exploratory and iterative process</font><br>\n",
    "\n",
    "## <font color=blue> -  Standard process is:   First, establish a functional model</font> \n",
    "\n",
    "## <font color=blue> -  This will give you a steer on what to focus on next</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps, in this case... search for best model hyperparameters using sklearn's GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 +) Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GridSearchCV takes in dict (or list of dicts) \n",
    "the dict contains parameter names as keys and parameter settings as values\n",
    "GridSearch then uses these various hyperparameter values to train multiple SVMs\n",
    "\n",
    "So...\n",
    "keys = params, values = list of settings to test.\n",
    "\n",
    "We know the parameters from looking at help for our instantiation call: classifier = SVC() \n",
    "\n",
    "Here we will try a Grid based on a range of C and gamma values.\n",
    "\n",
    "C in SVM is the penalty for misclassifying. High C value corresponds to strict margin.  Relaxing may help. <br>\n",
    "**Large C = low bias, high variance** ,so model is strictly trained to training data - overfitted - and can't generalise to test data).\n",
    "\n",
    "Gamma is the kernel coefficient (or it is when kernel is default = radial basis function).  It defines how far the influence a single training example reaches.  Intuitively, if gamma is high then each example exerts far recahing influence and gives potential for overfittig (high variance)  Thus gamma works in reverse way to C: <br> \n",
    "**Large gamma = High bias** , biased to model, rather than data, and thus low variance (low overfitting). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a parameter grid to explore the function of the SVM given a range of C and gamma parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid ={'C':[0.1, 1, 10, 100, 1000],\n",
    "            'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a GridSearch object with our classifier and parameter grid..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 +) Train (multiple) models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train multiple SVMs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the grid search believes are the best hyperparameter values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_ # C is increased to 10 instead of default 1.  Gamma is reduced to 0.0001 instead default 1/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pull out the score (gridsearch allocates a cross validation type score to each classifier in the grid)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is what the classifier (estimator) looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_grid_ is used above to refer to the highest scoring classifier.  We can take _grid_ and use it as our new (tuned) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 +) Re-evaluation - based on our gridsearch tuned classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a marked improvement comparing the above confusion matrix to our previous one. 9 out of 171 samples are misclassified (~5% misclassification)\n",
    "\n",
    "As before, we note:\n",
    "\n",
    "    There are 60 + 6 = 66 actual class 0 (malignant)\n",
    "    There are 3 + 102 = 105 actual class 1 (benign)\n",
    "\n",
    "However now we see that our SVM correctly finds 60 of the malignant tumours, a big improvement over our earlier SVM but unfortunately it classifies 6 malignant tumours as benign (false positives).  For cancer detection, this would be a worrying performance issue.\n",
    "\n",
    "There are 3 false negatives, which, given our labeling, corresponds to: benigns classed as malignant.  This would be acceptable in cancer detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class 0 = Malignant** <br>\n",
    "**Class 1 = Benign**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For class 0 (malignant), we have a recall of 0.91.  Whilst an improvement over earlier SVM, maximising this metric would be a priority in cancer detection.  The quality of the recall is high - precision = 0.95 - only a few benigns have been classed as malignant.\n",
    "\n",
    "For class 1 (benign), we have a recall of 0.97.  Most of the benigns are found.  Unfortunately as mentioned, **we are also pulling in some malignants here** hence our precision is not as high as we would like.  We would aspire to have the precision here = 1 (and recall for class 0 = 1) an aspiration which may require us to accept more benigns detected as malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Further work to improve the recall for class 0 based on revisting the second and third best SVMs from the grid.  (The grid's scoring system may have different priorities to our requirements.)  \n",
    "\n",
    "- Test effect of scaling the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> Return to step 3"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
